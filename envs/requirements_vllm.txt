# Requirements for vLLM backend environment
# Install with: pip install -r requirements_vllm.txt

# Core ML libraries
transformers>=4.49.0,<=4.57.1  # llamafactory requires <=4.57.1,>=4.49.0
datasets>=2.14.0

# Metrics dependencies
nltk>=3.8.0
rouge-score>=0.1.2

# Additional dependencies for various packages
colorama>=0.2.5,<0.4.7
webencodings>=0.5.0
scikit-learn>=1.1.0
decorator>=4.3.0  # Required by librosa
numba>=0.51.0  # Required by librosa
cycler>=0.10
fonttools>=4.22.0
kiwisolver>=1.3.1
nest_asyncio>=1.5.0
tenacity>=6.2.0
lxml>=4.0.0
markdown>=2.6.8

# Missing dependencies for various packages
defusedxml>=0.7.1
cryptography>=3.4.8
smmap>=5.0.0
more-itertools>=8.14.0
tornado>=6.1
chardet>=5.0.0
pyasn1>=0.4.8

# Version constraints for compatibility
# WARNING: llamafactory requires pydantic<=2.10.6, but openai-harmony requires pydantic>=2.11.7
# If you need openai-harmony, you may need to remove llamafactory or use separate environments
pydantic<=2.10.6  # Required by llamafactory (conflicts with openai-harmony>=2.11.7)
trl>=0.8.6,<=0.9.6  # Required by llamafactory
lark>=1.1.5,<1.2.0  # Required by pddl
outlines-core==0.1.26  # Required by outlines

# vLLM backend (requires torch==2.5.1, specified in envs/environment_vllm.yml)
vllm==0.6.5  # Pin version for compatibility

# Development dependencies
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.7.0
flake8>=6.1.0

